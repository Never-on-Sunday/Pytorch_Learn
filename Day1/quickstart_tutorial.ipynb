{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xy5SHYDbxna1"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKcbfuilxna4"
      },
      "source": [
        "[Learn the Basics](intro.html) \\|\\| **Quickstart** \\|\\|\n",
        "[Tensors](tensorqs_tutorial.html) \\|\\| [Datasets &\n",
        "DataLoaders](data_tutorial.html) \\|\\|\n",
        "[Transforms](transforms_tutorial.html) \\|\\| [Build\n",
        "Model](buildmodel_tutorial.html) \\|\\|\n",
        "[Autograd](autogradqs_tutorial.html) \\|\\|\n",
        "[Optimization](optimization_tutorial.html) \\|\\| [Save & Load\n",
        "Model](saveloadrun_tutorial.html)\n",
        "\n",
        "Quickstart\n",
        "==========\n",
        "\n",
        "This section runs through the API for common tasks in machine learning.\n",
        "Refer to the links in each section to dive deeper.\n",
        "\n",
        "Working with data\n",
        "-----------------\n",
        "\n",
        "PyTorch has two [primitives to work with\n",
        "data](https://pytorch.org/docs/stable/data.html):\n",
        "`torch.utils.data.DataLoader` and `torch.utils.data.Dataset`. `Dataset`\n",
        "stores the samples and their corresponding labels, and `DataLoader`\n",
        "wraps an iterable around the `Dataset`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0Gem5Z9Pxna6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TBD65uKxna6"
      },
      "source": [
        "PyTorch offers domain-specific libraries such as\n",
        "[TorchText](https://pytorch.org/text/stable/index.html),\n",
        "[TorchVision](https://pytorch.org/vision/stable/index.html), and\n",
        "[TorchAudio](https://pytorch.org/audio/stable/index.html), all of which\n",
        "include datasets. For this tutorial, we will be using a TorchVision\n",
        "dataset.\n",
        "\n",
        "The `torchvision.datasets` module contains `Dataset` objects for many\n",
        "real-world vision data like CIFAR, COCO ([full list\n",
        "here](https://pytorch.org/vision/stable/datasets.html)). In this\n",
        "tutorial, we use the FashionMNIST dataset. Every TorchVision `Dataset`\n",
        "includes two arguments: `transform` and `target_transform` to modify the\n",
        "samples and labels respectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKqsTobMxna7",
        "outputId": "b94e98f3-e090-432c-cacc-d4e7ff9cb936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 13.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 207kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.87MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 7.65MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R9f2La9zkQ8",
        "outputId": "b6b399e4-dbf2-4eae-a2f2-a79f115bfbab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# Load FashionMNIST without applying ToTensor()\n",
        "dataset = FashionMNIST(root=\"data\", train=True, download=True)\n",
        "\n",
        "# Get the first image and label\n",
        "image, label = dataset[0]\n",
        "\n",
        "print(type(image))  # Output: <class 'PIL.Image.Image'>\n",
        "print(image.size)   # Output: (28, 28)  # Size of the image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxdVbEYq0bqc",
        "outputId": "35b73c79-ad38-47bd-c925-c7b09416526e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'PIL.Image.Image'>\n",
            "(28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "id": "AX8X9TLu26Wl",
        "outputId": "3303b24d-1f8b-48f0-8c65-987ce185637a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Load FashionMNIST with ToTensor transformation\n",
        "dataset = FashionMNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
        "\n",
        "# Get the first image and label\n",
        "image, label = dataset[0]\n",
        "\n",
        "print(type(image))  # Output: <class 'torch.Tensor'>\n",
        "print(image.shape)  # Output: torch.Size([1, 28, 28])  # Shape: [Channels, Height, Width]\n",
        "print(image.min(), image.max())  # Output: tensor(0.0) tensor(1.0)\n"
      ],
      "metadata": {
        "id": "iYqicaz-2l_X",
        "outputId": "f323ae12-03a9-4ae4-ad59-5624312efa63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 28, 28])\n",
            "tensor(0.) tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Without ToTensor\n",
        "image_pil, _ = FashionMNIST(root=\"data\", train=True, download=True)[0]\n",
        "\n",
        "# With ToTensor\n",
        "image_tensor, _ = FashionMNIST(root=\"data\", train=True, download=True, transform=ToTensor())[0]\n",
        "\n",
        "# Plot the PIL image\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Without ToTensor (PIL)\")\n",
        "plt.imshow(image_pil, cmap=\"gray\")\n",
        "\n",
        "# Plot the tensor image (convert to NumPy for visualization)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"With ToTensor (Tensor)\")\n",
        "plt.imshow(image_tensor.squeeze(0).numpy(), cmap=\"gray\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "b1DZ1_nF2wXJ",
        "outputId": "10afe484-f859-416f-d12c-bfdfaf2100d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Create a tensor with a single channel dimension\n",
        "tensor = torch.randn(1, 1, 4, 1, 4)  # Shape: [1, 4, 4]\n",
        "\n",
        "print(\"Original tensor shape:\", tensor.shape)\n",
        "# Remove the channel dimension (dim=0) using squeeze\n",
        "squeezed_tensor = tensor.squeeze(3)  # Removes the first dimension (size=1)\n",
        "\n",
        "print(\"Squeezed tensor shape:\", squeezed_tensor.shape)"
      ],
      "metadata": {
        "id": "objUxloT3v-5",
        "outputId": "ebde9ade-f21e-465a-fdc4-499a7f908927",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor shape: torch.Size([1, 1, 4, 1, 4])\n",
            "Squeezed tensor shape: torch.Size([1, 1, 4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_tensor.squeeze(0).numpy()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "E-V_zij35rmx",
        "outputId": "b8e922b3-f57b-4bd1-9766-c82febecd3f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
              "        0.05098039, 0.28627452, 0.        , 0.        , 0.00392157,\n",
              "        0.01568628, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00392157, 0.00392157, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01176471, 0.        , 0.14117648,\n",
              "        0.53333336, 0.49803922, 0.24313726, 0.21176471, 0.        ,\n",
              "        0.        , 0.        , 0.00392157, 0.01176471, 0.01568628,\n",
              "        0.        , 0.        , 0.01176471],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
              "        0.8       , 0.6901961 , 0.5254902 , 0.5647059 , 0.48235294,\n",
              "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.04705882, 0.03921569, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.60784316,\n",
              "        0.9254902 , 0.8117647 , 0.69803923, 0.41960785, 0.6117647 ,\n",
              "        0.6313726 , 0.42745098, 0.2509804 , 0.09019608, 0.3019608 ,\n",
              "        0.50980395, 0.28235295, 0.05882353],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.27058825, 0.8117647 ,\n",
              "        0.8745098 , 0.85490197, 0.84705883, 0.84705883, 0.6392157 ,\n",
              "        0.49803922, 0.4745098 , 0.47843137, 0.57254905, 0.5529412 ,\n",
              "        0.34509805, 0.6745098 , 0.25882354],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.        , 0.78431374, 0.9098039 ,\n",
              "        0.9098039 , 0.9137255 , 0.8980392 , 0.8745098 , 0.8745098 ,\n",
              "        0.84313726, 0.8352941 , 0.6431373 , 0.49803922, 0.48235294,\n",
              "        0.76862746, 0.8980392 , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.7176471 , 0.88235295,\n",
              "        0.84705883, 0.8745098 , 0.89411765, 0.92156863, 0.8901961 ,\n",
              "        0.8784314 , 0.87058824, 0.8784314 , 0.8666667 , 0.8745098 ,\n",
              "        0.9607843 , 0.6784314 , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.75686276, 0.89411765,\n",
              "        0.85490197, 0.8352941 , 0.7764706 , 0.7058824 , 0.83137256,\n",
              "        0.8235294 , 0.827451  , 0.8352941 , 0.8745098 , 0.8627451 ,\n",
              "        0.9529412 , 0.7921569 , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.01176471, 0.        , 0.04705882, 0.85882354, 0.8627451 ,\n",
              "        0.83137256, 0.85490197, 0.7529412 , 0.6627451 , 0.8901961 ,\n",
              "        0.8156863 , 0.85490197, 0.8784314 , 0.83137256, 0.8862745 ,\n",
              "        0.77254903, 0.81960785, 0.20392157],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.02352941, 0.        , 0.3882353 , 0.95686275, 0.87058824,\n",
              "        0.8627451 , 0.85490197, 0.79607844, 0.7764706 , 0.8666667 ,\n",
              "        0.84313726, 0.8352941 , 0.87058824, 0.8627451 , 0.9607843 ,\n",
              "        0.46666667, 0.654902  , 0.21960784],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.01568628,\n",
              "        0.        , 0.        , 0.21568628, 0.9254902 , 0.89411765,\n",
              "        0.9019608 , 0.89411765, 0.9411765 , 0.9098039 , 0.8352941 ,\n",
              "        0.85490197, 0.8745098 , 0.91764706, 0.8509804 , 0.8509804 ,\n",
              "        0.81960785, 0.36078432, 0.        ],\n",
              "       [0.        , 0.        , 0.00392157, 0.01568628, 0.02352941,\n",
              "        0.02745098, 0.00784314, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.92941177, 0.8862745 , 0.8509804 ,\n",
              "        0.8745098 , 0.87058824, 0.85882354, 0.87058824, 0.8666667 ,\n",
              "        0.84705883, 0.8745098 , 0.8980392 , 0.84313726, 0.85490197,\n",
              "        1.        , 0.3019608 , 0.        ],\n",
              "       [0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.24313726,\n",
              "        0.5686275 , 0.8       , 0.89411765, 0.8117647 , 0.8352941 ,\n",
              "        0.8666667 , 0.85490197, 0.8156863 , 0.827451  , 0.85490197,\n",
              "        0.8784314 , 0.8745098 , 0.85882354, 0.84313726, 0.8784314 ,\n",
              "        0.95686275, 0.62352943, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
              "        0.17254902, 0.32156864, 0.41960785, 0.7411765 , 0.89411765,\n",
              "        0.8627451 , 0.87058824, 0.8509804 , 0.8862745 , 0.78431374,\n",
              "        0.8039216 , 0.827451  , 0.9019608 , 0.8784314 , 0.91764706,\n",
              "        0.6901961 , 0.7372549 , 0.98039216, 0.972549  , 0.9137255 ,\n",
              "        0.93333334, 0.84313726, 0.        ],\n",
              "       [0.        , 0.22352941, 0.73333335, 0.8156863 , 0.8784314 ,\n",
              "        0.8666667 , 0.8784314 , 0.8156863 , 0.8       , 0.8392157 ,\n",
              "        0.8156863 , 0.81960785, 0.78431374, 0.62352943, 0.9607843 ,\n",
              "        0.75686276, 0.80784315, 0.8745098 , 1.        , 1.        ,\n",
              "        0.8666667 , 0.91764706, 0.8666667 , 0.827451  , 0.8627451 ,\n",
              "        0.9098039 , 0.9647059 , 0.        ],\n",
              "       [0.01176471, 0.7921569 , 0.89411765, 0.8784314 , 0.8666667 ,\n",
              "        0.827451  , 0.827451  , 0.8392157 , 0.8039216 , 0.8039216 ,\n",
              "        0.8039216 , 0.8627451 , 0.9411765 , 0.3137255 , 0.5882353 ,\n",
              "        1.        , 0.8980392 , 0.8666667 , 0.7372549 , 0.6039216 ,\n",
              "        0.7490196 , 0.8235294 , 0.8       , 0.81960785, 0.87058824,\n",
              "        0.89411765, 0.88235295, 0.        ],\n",
              "       [0.38431373, 0.9137255 , 0.7764706 , 0.8235294 , 0.87058824,\n",
              "        0.8980392 , 0.8980392 , 0.91764706, 0.9764706 , 0.8627451 ,\n",
              "        0.7607843 , 0.84313726, 0.8509804 , 0.94509804, 0.25490198,\n",
              "        0.28627452, 0.41568628, 0.45882353, 0.65882355, 0.85882354,\n",
              "        0.8666667 , 0.84313726, 0.8509804 , 0.8745098 , 0.8745098 ,\n",
              "        0.8784314 , 0.8980392 , 0.11372549],\n",
              "       [0.29411766, 0.8       , 0.83137256, 0.8       , 0.75686276,\n",
              "        0.8039216 , 0.827451  , 0.88235295, 0.84705883, 0.7254902 ,\n",
              "        0.77254903, 0.80784315, 0.7764706 , 0.8352941 , 0.9411765 ,\n",
              "        0.7647059 , 0.8901961 , 0.9607843 , 0.9372549 , 0.8745098 ,\n",
              "        0.85490197, 0.83137256, 0.81960785, 0.87058824, 0.8627451 ,\n",
              "        0.8666667 , 0.9019608 , 0.2627451 ],\n",
              "       [0.1882353 , 0.79607844, 0.7176471 , 0.7607843 , 0.8352941 ,\n",
              "        0.77254903, 0.7254902 , 0.74509805, 0.7607843 , 0.7529412 ,\n",
              "        0.7921569 , 0.8392157 , 0.85882354, 0.8666667 , 0.8627451 ,\n",
              "        0.9254902 , 0.88235295, 0.84705883, 0.78039217, 0.80784315,\n",
              "        0.7294118 , 0.70980394, 0.69411767, 0.6745098 , 0.70980394,\n",
              "        0.8039216 , 0.80784315, 0.4509804 ],\n",
              "       [0.        , 0.47843137, 0.85882354, 0.75686276, 0.7019608 ,\n",
              "        0.67058825, 0.7176471 , 0.76862746, 0.8       , 0.8235294 ,\n",
              "        0.8352941 , 0.8117647 , 0.827451  , 0.8235294 , 0.78431374,\n",
              "        0.76862746, 0.7607843 , 0.7490196 , 0.7647059 , 0.7490196 ,\n",
              "        0.7764706 , 0.7529412 , 0.6901961 , 0.6117647 , 0.654902  ,\n",
              "        0.69411767, 0.8235294 , 0.36078432],\n",
              "       [0.        , 0.        , 0.2901961 , 0.7411765 , 0.83137256,\n",
              "        0.7490196 , 0.6862745 , 0.6745098 , 0.6862745 , 0.70980394,\n",
              "        0.7254902 , 0.7372549 , 0.7411765 , 0.7372549 , 0.75686276,\n",
              "        0.7764706 , 0.8       , 0.81960785, 0.8235294 , 0.8235294 ,\n",
              "        0.827451  , 0.7372549 , 0.7372549 , 0.7607843 , 0.7529412 ,\n",
              "        0.84705883, 0.6666667 , 0.        ],\n",
              "       [0.00784314, 0.        , 0.        , 0.        , 0.25882354,\n",
              "        0.78431374, 0.87058824, 0.92941177, 0.9372549 , 0.9490196 ,\n",
              "        0.9647059 , 0.9529412 , 0.95686275, 0.8666667 , 0.8627451 ,\n",
              "        0.75686276, 0.7490196 , 0.7019608 , 0.7137255 , 0.7137255 ,\n",
              "        0.70980394, 0.6901961 , 0.6509804 , 0.65882355, 0.3882353 ,\n",
              "        0.22745098, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
              "        0.28235295, 0.16078432, 0.13725491, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqIWBwlLxna7"
      },
      "source": [
        "We pass the `Dataset` as an argument to `DataLoader`. This wraps an\n",
        "iterable over our dataset, and supports automatic batching, sampling,\n",
        "shuffling and multiprocess data loading. Here we define a batch size of\n",
        "64, i.e. each element in the dataloader iterable will return a batch of\n",
        "64 features and labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mThB6X0hxna8",
        "outputId": "a650f356-9e72-4592-9466-dacf85e9ee65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Tem1TIYxna8"
      },
      "source": [
        "Read more about [loading data in PyTorch](data_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvqD6_PFxna9"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ahx6Ro8Oxna9"
      },
      "source": [
        "Creating Models\n",
        "===============\n",
        "\n",
        "To define a neural network in PyTorch, we create a class that inherits\n",
        "from\n",
        "[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n",
        "We define the layers of the network in the `__init__` function and\n",
        "specify how data will pass through the network in the `forward`\n",
        "function. To accelerate operations in the neural network, we move it to\n",
        "the GPU or MPS if available.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "LoHiTI449rRN",
        "outputId": "46b05ee0-508a-4fdc-b5de-743bec77198b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.backends.mps.is_available()"
      ],
      "metadata": {
        "id": "Yr13SWYl9uR3",
        "outputId": "08ca7ed3-8b48-4181-8582-deed0f87e026",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cpu"
      ],
      "metadata": {
        "id": "mMuI-luV-YUS",
        "outputId": "b93cd561-7cbf-4f27-9645-c957eb226013",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'torch.cpu' from '/usr/local/lib/python3.10/dist-packages/torch/cpu/__init__.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45HdU6u3xna9",
        "outputId": "65d6b649-fdb2-4845-97fd-5207075f3043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ucYSWIexna9"
      },
      "source": [
        "Read more about [building neural networks in\n",
        "PyTorch](buildmodel_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt4uEV2kxna-"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OryOriWcxna-"
      },
      "source": [
        "Optimizing the Model Parameters\n",
        "===============================\n",
        "\n",
        "To train a model, we need a [loss\n",
        "function](https://pytorch.org/docs/stable/nn.html#loss-functions) and an\n",
        "[optimizer](https://pytorch.org/docs/stable/optim.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TFynVglIxna-"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqObFEuWxna-"
      },
      "source": [
        "In a single training loop, the model makes predictions on the training\n",
        "dataset (fed to it in batches), and backpropagates the prediction error\n",
        "to adjust the model\\'s parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "g-of1atTEdBE",
        "outputId": "be1f00ad-c74f-4a17-9b05-5a23a4999170",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "0HpyK5eGxna-"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTTGnCobxna_"
      },
      "source": [
        "We also check the model\\'s performance against the test dataset to\n",
        "ensure it is learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "rCiAFqMsxna_"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FgZ0vECxna_"
      },
      "source": [
        "The training process is conducted over several iterations (*epochs*).\n",
        "During each epoch, the model learns parameters to make better\n",
        "predictions. We print the model\\'s accuracy and loss at each epoch;\n",
        "we\\'d like to see the accuracy increase and the loss decrease with every\n",
        "epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl7XfKbPxna_",
        "outputId": "d817656e-bb62-4f7d-8e09-ed26ed56397e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.309258  [   64/60000]\n",
            "loss: 2.301560  [ 6464/60000]\n",
            "loss: 2.281779  [12864/60000]\n",
            "loss: 2.271621  [19264/60000]\n",
            "loss: 2.263989  [25664/60000]\n",
            "loss: 2.220370  [32064/60000]\n",
            "loss: 2.236022  [38464/60000]\n",
            "loss: 2.200984  [44864/60000]\n",
            "loss: 2.194708  [51264/60000]\n",
            "loss: 2.167877  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 33.3%, Avg loss: 2.164740 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.174001  [   64/60000]\n",
            "loss: 2.168783  [ 6464/60000]\n",
            "loss: 2.112257  [12864/60000]\n",
            "loss: 2.127257  [19264/60000]\n",
            "loss: 2.078972  [25664/60000]\n",
            "loss: 2.007810  [32064/60000]\n",
            "loss: 2.046914  [38464/60000]\n",
            "loss: 1.971034  [44864/60000]\n",
            "loss: 1.972161  [51264/60000]\n",
            "loss: 1.905736  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 54.4%, Avg loss: 1.908734 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.937619  [   64/60000]\n",
            "loss: 1.907431  [ 6464/60000]\n",
            "loss: 1.801768  [12864/60000]\n",
            "loss: 1.844984  [19264/60000]\n",
            "loss: 1.725331  [25664/60000]\n",
            "loss: 1.673286  [32064/60000]\n",
            "loss: 1.709886  [38464/60000]\n",
            "loss: 1.615954  [44864/60000]\n",
            "loss: 1.633131  [51264/60000]\n",
            "loss: 1.535399  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 61.3%, Avg loss: 1.555602 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.617520  [   64/60000]\n",
            "loss: 1.577459  [ 6464/60000]\n",
            "loss: 1.442418  [12864/60000]\n",
            "loss: 1.507039  [19264/60000]\n",
            "loss: 1.381422  [25664/60000]\n",
            "loss: 1.373524  [32064/60000]\n",
            "loss: 1.398440  [38464/60000]\n",
            "loss: 1.327623  [44864/60000]\n",
            "loss: 1.348665  [51264/60000]\n",
            "loss: 1.253603  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.3%, Avg loss: 1.282959 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.358568  [   64/60000]\n",
            "loss: 1.333947  [ 6464/60000]\n",
            "loss: 1.180473  [12864/60000]\n",
            "loss: 1.270817  [19264/60000]\n",
            "loss: 1.145526  [25664/60000]\n",
            "loss: 1.163545  [32064/60000]\n",
            "loss: 1.196307  [38464/60000]\n",
            "loss: 1.137936  [44864/60000]\n",
            "loss: 1.162431  [51264/60000]\n",
            "loss: 1.080078  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.8%, Avg loss: 1.106311 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3sxIXP-xna_"
      },
      "source": [
        "Read more about [Training your model](optimization_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfT5IRP1xna_"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_OgHGAqxna_"
      },
      "source": [
        "Saving Models\n",
        "=============\n",
        "\n",
        "A common way to save a model is to serialize the internal state\n",
        "dictionary (containing the model parameters).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ann1NZ0xnbA",
        "outputId": "50cce142-3449-42aa-ee41-4579dc59af7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BcfqjaAxnbA"
      },
      "source": [
        "Loading Models\n",
        "==============\n",
        "\n",
        "The process for loading a model includes re-creating the model structure\n",
        "and loading the state dictionary into it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4vE_VX1xnbA",
        "outputId": "b5dfc836-ad97-49fd-ca56-0b47e96fcb77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6gA66utxnbA"
      },
      "source": [
        "This model can now be used to make predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP9ayMp3xnbA",
        "outputId": "7521080b-6451-4143-8530-7e00ca6c3fe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ],
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFCeRb4wxnbA"
      },
      "source": [
        "Read more about [Saving & Loading your\n",
        "model](saveloadrun_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "4_cHU_vPPi3b",
        "outputId": "0522b260-1e4d-410d-b5cb-2006178fe1bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('linear_relu_stack.0.weight', tensor([[ 0.0304,  0.0133,  0.0269,  ...,  0.0119, -0.0302,  0.0356],\n",
            "        [ 0.0189, -0.0303, -0.0246,  ...,  0.0264, -0.0024, -0.0127],\n",
            "        [-0.0287,  0.0176,  0.0097,  ...,  0.0150, -0.0199,  0.0290],\n",
            "        ...,\n",
            "        [-0.0269, -0.0143, -0.0179,  ...,  0.0298,  0.0290,  0.0104],\n",
            "        [-0.0089, -0.0299,  0.0129,  ..., -0.0008,  0.0187,  0.0173],\n",
            "        [-0.0261,  0.0158, -0.0212,  ..., -0.0096, -0.0046,  0.0139]],\n",
            "       device='cuda:0')), ('linear_relu_stack.0.bias', tensor([ 1.9580e-03, -1.5295e-02,  3.0064e-02,  1.8931e-03,  9.0409e-03,\n",
            "        -2.1047e-02, -3.5775e-02,  2.6454e-02, -2.2649e-02, -3.2153e-02,\n",
            "        -1.0577e-02,  1.9502e-02, -2.4501e-02,  7.2165e-03, -1.8650e-02,\n",
            "        -2.8261e-02,  3.3240e-02, -8.0117e-03,  2.1212e-02,  1.8400e-02,\n",
            "        -3.4555e-05, -1.3904e-03,  3.0873e-02,  3.1764e-02, -2.1185e-03,\n",
            "        -2.1526e-02, -1.5982e-02,  2.9396e-02, -2.2566e-02,  2.1451e-03,\n",
            "         1.0984e-02,  2.2626e-02, -2.1699e-02,  2.2392e-02,  1.3285e-02,\n",
            "         3.5579e-02,  2.0914e-02, -2.7659e-02,  1.0359e-02,  2.3348e-02,\n",
            "        -3.4260e-02, -1.1007e-02, -3.9630e-04, -3.5312e-02,  1.6575e-02,\n",
            "         1.6271e-02,  1.1976e-02,  3.7250e-02, -3.2591e-03, -2.3632e-02,\n",
            "        -5.3239e-03, -9.8903e-03,  1.3955e-02,  2.1054e-02,  2.1258e-02,\n",
            "        -2.2408e-02,  3.4427e-02,  3.9252e-02, -3.6398e-05, -2.8437e-02,\n",
            "        -1.0650e-02, -2.4578e-03, -2.8308e-02,  4.9840e-03, -1.1845e-02,\n",
            "         4.1891e-02, -3.1057e-02,  2.3327e-02,  1.0938e-02, -5.0441e-03,\n",
            "        -1.8417e-02, -1.0133e-02,  2.5553e-02, -8.8884e-03, -2.3424e-02,\n",
            "         2.4223e-02, -4.5898e-03, -6.1997e-03, -1.6264e-02,  1.0347e-03,\n",
            "         8.5962e-03, -9.6064e-04, -1.7063e-02,  3.3221e-02,  2.5174e-03,\n",
            "        -4.9350e-04, -8.0968e-03, -2.8314e-02,  3.2777e-02, -3.1671e-02,\n",
            "        -2.2174e-02, -3.3461e-02, -2.6424e-02,  3.0272e-02,  3.5065e-02,\n",
            "         2.5267e-02, -2.4372e-02,  1.6872e-02,  8.3150e-03,  5.4810e-03,\n",
            "         2.3935e-02,  2.9382e-02, -8.2013e-03,  3.9856e-02, -8.5980e-03,\n",
            "         3.8963e-02, -1.4131e-02,  1.0478e-02, -1.8675e-02, -2.9177e-02,\n",
            "         1.7889e-02, -2.9565e-02,  2.6920e-02, -2.9558e-03,  5.6116e-03,\n",
            "        -2.4565e-02, -3.2199e-03, -3.3239e-02,  1.8615e-03, -2.2342e-02,\n",
            "         2.5404e-02, -1.2106e-02, -2.4425e-02, -8.9612e-03,  7.8828e-05,\n",
            "         3.4799e-02,  7.7944e-03, -3.3405e-02, -1.4343e-02,  9.8752e-03,\n",
            "         2.5771e-02, -1.6683e-02,  2.4753e-02, -1.9121e-02,  3.8646e-02,\n",
            "         2.9286e-02,  1.1516e-02, -2.6013e-02,  1.4035e-02, -2.4462e-02,\n",
            "        -4.2876e-03,  4.7205e-02, -2.3109e-02, -1.9086e-02, -1.4234e-02,\n",
            "        -1.5464e-02,  4.8477e-03,  2.5210e-03,  1.9028e-02,  3.4977e-02,\n",
            "        -1.8433e-02, -3.2475e-02,  2.6629e-02,  6.8385e-03,  3.0209e-02,\n",
            "        -5.4170e-03, -3.6833e-03, -1.3209e-02, -3.0621e-02,  2.8064e-04,\n",
            "         2.3037e-02, -1.9200e-02, -3.4314e-02,  5.1599e-03,  5.1755e-03,\n",
            "         2.4543e-02, -2.2433e-02,  2.3265e-02, -1.7363e-02, -1.9269e-02,\n",
            "        -2.7376e-02,  5.1298e-03, -2.6265e-03,  2.9160e-02,  1.3383e-02,\n",
            "         1.0914e-02,  6.9479e-03, -4.4163e-04,  1.2639e-02, -2.4103e-02,\n",
            "         3.3368e-02, -2.4689e-02, -2.6118e-02,  4.0718e-03,  3.4161e-02,\n",
            "        -4.1478e-03, -6.9709e-03,  2.7012e-02, -2.2423e-02,  1.9792e-02,\n",
            "        -2.6719e-02, -1.6961e-02,  3.0450e-02,  2.5442e-02,  3.6677e-04,\n",
            "        -1.2973e-02, -1.9332e-02, -2.3190e-02,  7.3474e-03,  3.0055e-02,\n",
            "        -3.1797e-02,  1.1096e-02, -1.6124e-02,  2.4059e-02, -2.2846e-02,\n",
            "        -1.2120e-04, -9.0957e-03, -2.4010e-02,  8.0031e-03,  2.1129e-02,\n",
            "         3.5858e-02, -1.9181e-02, -2.6201e-02, -4.2664e-04,  3.5704e-02,\n",
            "         1.9507e-02,  2.0873e-02, -5.7650e-05, -4.9203e-03, -1.3656e-02,\n",
            "         9.6522e-03, -2.4242e-03,  1.6371e-02,  2.8346e-02, -1.4510e-02,\n",
            "         1.0531e-02,  1.3485e-02, -2.9515e-02,  3.3229e-02, -1.2269e-02,\n",
            "         1.1737e-02, -2.0700e-02, -1.9184e-02, -2.7965e-02, -3.5073e-02,\n",
            "        -2.4243e-02,  2.7808e-02, -8.1310e-03,  3.2167e-02, -3.3860e-02,\n",
            "         3.1286e-03, -2.5536e-02,  1.3335e-02, -4.4190e-03,  3.5043e-02,\n",
            "        -2.8459e-02, -2.5729e-02, -1.7174e-02,  5.8607e-03, -1.4526e-02,\n",
            "         1.7332e-02, -2.4026e-02,  1.0135e-02, -4.8315e-03,  2.9542e-02,\n",
            "        -1.8245e-02,  3.3074e-02, -2.3705e-03,  3.8921e-03,  1.1507e-03,\n",
            "         5.6993e-03,  3.8984e-02, -2.0991e-02, -1.0523e-02, -2.8990e-02,\n",
            "        -2.2974e-02, -1.7557e-02,  2.1663e-03, -3.1517e-02, -5.4960e-03,\n",
            "         1.3056e-02, -6.7864e-03,  1.8210e-02,  9.7099e-03,  3.0248e-02,\n",
            "        -1.5422e-02, -4.1175e-03, -3.2605e-02,  3.4570e-02,  1.2007e-02,\n",
            "         4.2185e-04,  2.5334e-02,  1.8330e-03, -9.9562e-03, -2.8296e-02,\n",
            "         3.0754e-02,  2.5479e-02,  1.2282e-02, -1.0665e-02,  1.4299e-02,\n",
            "        -1.0920e-02, -1.8863e-02, -2.6925e-02,  2.8277e-02,  1.6573e-02,\n",
            "        -1.7276e-02, -2.1724e-03, -3.3295e-02, -1.6788e-02,  4.9407e-04,\n",
            "         2.7738e-02, -2.7273e-02,  2.6922e-02,  5.6021e-03,  1.3607e-02,\n",
            "        -3.3391e-02,  2.6913e-02, -3.2493e-02, -2.4208e-02, -2.2792e-02,\n",
            "         1.1775e-02,  7.4304e-03, -1.2313e-02,  1.2824e-02,  1.1509e-02,\n",
            "         3.2697e-02, -7.2418e-03,  3.9594e-03,  1.0529e-03,  3.5724e-02,\n",
            "         1.4478e-02,  2.3708e-02,  4.7182e-04,  9.6647e-03,  3.3663e-02,\n",
            "        -2.7583e-03, -1.8137e-02,  1.0149e-02,  2.1277e-02,  2.2249e-02,\n",
            "         3.0753e-02, -2.1408e-02,  2.6007e-02,  4.6858e-03,  3.4986e-02,\n",
            "        -3.1550e-02, -1.3608e-02,  3.4444e-02, -3.2161e-02, -3.5570e-02,\n",
            "         9.4533e-03, -3.3018e-02, -1.7652e-02,  1.9228e-02,  9.1829e-03,\n",
            "        -3.0625e-03, -1.0464e-02, -1.9324e-02,  1.4086e-02, -1.7705e-02,\n",
            "        -3.3135e-02, -2.9525e-02, -3.3567e-04,  1.8430e-02,  3.4334e-02,\n",
            "        -2.7227e-02, -1.4795e-02, -1.1042e-02,  3.3352e-02,  2.2846e-02,\n",
            "        -1.3746e-02,  2.4364e-02, -1.3406e-02, -2.2831e-02,  3.8117e-02,\n",
            "        -1.2653e-02,  3.4587e-02,  3.5554e-02,  3.8268e-02, -1.4241e-02,\n",
            "         3.8964e-02, -6.7193e-03,  1.6043e-03, -2.3699e-02, -2.3340e-02,\n",
            "         1.0861e-02, -5.4455e-03,  3.1196e-04, -1.7922e-02, -2.8597e-02,\n",
            "         3.4775e-02,  8.1404e-03, -1.7527e-03, -2.3168e-02,  3.3312e-03,\n",
            "        -2.6750e-02, -2.0023e-02, -1.9928e-02,  4.0746e-03,  2.8558e-02,\n",
            "        -1.1198e-02,  1.0411e-02, -1.9678e-02, -3.0073e-02, -1.0332e-02,\n",
            "        -1.4008e-02,  2.0468e-02, -5.6905e-03,  2.0993e-02,  4.8603e-04,\n",
            "        -2.0208e-02, -1.5582e-02, -1.8495e-02,  2.8472e-02, -5.0635e-03,\n",
            "         2.7008e-02,  2.7958e-02,  1.9853e-02,  1.4491e-02, -1.1773e-02,\n",
            "         1.2680e-03,  2.1228e-02, -2.2925e-02, -2.2396e-02, -1.8897e-02,\n",
            "        -3.7460e-02, -1.3280e-02, -4.7373e-03, -2.1367e-02,  2.4433e-02,\n",
            "        -3.1627e-02,  3.4598e-02, -7.7741e-03, -6.6322e-03, -1.6025e-02,\n",
            "        -2.0154e-02,  5.2504e-03,  3.1222e-02,  4.1343e-02, -2.5060e-02,\n",
            "         2.0358e-02, -7.4097e-03, -2.2083e-02,  2.8192e-02, -1.9983e-03,\n",
            "        -2.6978e-02,  4.1123e-03,  3.2091e-02,  1.5531e-02, -7.3642e-03,\n",
            "         2.6106e-02, -2.8392e-02, -2.3826e-02,  3.9550e-02,  3.2546e-02,\n",
            "        -2.4185e-03, -2.1185e-02,  1.7267e-02,  7.8535e-03, -1.5607e-02,\n",
            "        -3.4383e-02, -5.5039e-03,  1.3428e-02,  2.5299e-02,  1.5607e-02,\n",
            "         2.5382e-03, -1.2149e-02,  9.8206e-03, -3.2441e-02, -3.5190e-02,\n",
            "         1.9508e-02,  1.0402e-02, -2.6132e-02,  1.8668e-02, -2.9570e-02,\n",
            "         1.4510e-02,  6.4999e-03,  7.0807e-03,  1.5905e-03,  2.4458e-02,\n",
            "         2.8343e-02, -2.5794e-02, -1.5543e-02,  8.6780e-03,  2.7278e-03,\n",
            "         2.1347e-02,  3.0951e-02,  1.4183e-02,  3.2127e-02, -3.0294e-02,\n",
            "         9.5505e-03,  1.1514e-02, -2.7845e-02,  7.6344e-03, -2.7843e-02,\n",
            "         3.3748e-02, -4.1379e-04,  3.7010e-02,  2.9295e-04, -2.5418e-02,\n",
            "         2.6550e-02, -1.0192e-02, -2.5337e-02,  4.4888e-03,  9.9360e-03,\n",
            "        -2.2449e-02,  3.1405e-02, -9.6398e-03, -7.6664e-04, -2.7154e-03,\n",
            "         3.0257e-02,  6.5488e-03, -5.2852e-03, -1.0556e-02, -2.5095e-02,\n",
            "         3.5538e-02, -2.5324e-02, -9.1505e-03,  7.0849e-03, -2.6541e-02,\n",
            "         3.5567e-02, -3.8072e-03], device='cuda:0')), ('linear_relu_stack.2.weight', tensor([[ 0.0388,  0.0360,  0.0157,  ..., -0.0407,  0.0272,  0.0205],\n",
            "        [-0.0191,  0.0423, -0.0190,  ...,  0.0381, -0.0150,  0.0352],\n",
            "        [-0.0400,  0.0176,  0.0006,  ..., -0.0062,  0.0377,  0.0408],\n",
            "        ...,\n",
            "        [-0.0168,  0.0159, -0.0235,  ..., -0.0155, -0.0263, -0.0246],\n",
            "        [-0.0253, -0.0102,  0.0041,  ...,  0.0020, -0.0272, -0.0279],\n",
            "        [-0.0308, -0.0425, -0.0315,  ..., -0.0015,  0.0119,  0.0398]],\n",
            "       device='cuda:0')), ('linear_relu_stack.2.bias', tensor([-0.0084,  0.0171, -0.0152, -0.0311,  0.0103,  0.0240, -0.0157,  0.0312,\n",
            "         0.0312,  0.0061,  0.0164, -0.0098, -0.0088, -0.0142,  0.0360,  0.0552,\n",
            "        -0.0244,  0.0192,  0.0433,  0.0197,  0.0354, -0.0448,  0.0003,  0.0414,\n",
            "        -0.0034,  0.0294,  0.0325,  0.0382,  0.0255, -0.0169,  0.0111, -0.0191,\n",
            "         0.0075, -0.0271, -0.0178,  0.0125, -0.0323, -0.0085, -0.0301,  0.0288,\n",
            "         0.0181,  0.0055,  0.0010, -0.0202,  0.0113, -0.0379, -0.0408, -0.0422,\n",
            "        -0.0408, -0.0182,  0.0325,  0.0349,  0.0108, -0.0202,  0.0283,  0.0498,\n",
            "        -0.0376, -0.0171, -0.0330,  0.0623,  0.0265,  0.0355,  0.0496,  0.0610,\n",
            "        -0.0077, -0.0118,  0.0225, -0.0177, -0.0058, -0.0203, -0.0078,  0.0078,\n",
            "         0.0163,  0.0505, -0.0147, -0.0013,  0.0447,  0.0023,  0.0253,  0.0024,\n",
            "        -0.0313, -0.0406, -0.0063,  0.0071,  0.0328, -0.0351,  0.0350,  0.0298,\n",
            "        -0.0218, -0.0025,  0.0276,  0.0032,  0.0117, -0.0068,  0.0356, -0.0117,\n",
            "        -0.0115, -0.0125, -0.0315, -0.0129, -0.0421, -0.0338, -0.0340,  0.0343,\n",
            "        -0.0293,  0.0102, -0.0217, -0.0241, -0.0200,  0.0441,  0.0194,  0.0364,\n",
            "         0.0005, -0.0124, -0.0444, -0.0328, -0.0246,  0.0396, -0.0430,  0.0093,\n",
            "        -0.0255,  0.0515,  0.0329, -0.0064, -0.0057,  0.0024,  0.0187,  0.0580,\n",
            "        -0.0245,  0.0050,  0.0230, -0.0387,  0.0135, -0.0297, -0.0117, -0.0288,\n",
            "         0.0400, -0.0138,  0.0356,  0.0338, -0.0218,  0.0281, -0.0080, -0.0269,\n",
            "         0.0224, -0.0208, -0.0327,  0.0236,  0.0346, -0.0410, -0.0169, -0.0065,\n",
            "         0.0222,  0.0160,  0.0287,  0.0541,  0.0486,  0.0088, -0.0006, -0.0106,\n",
            "         0.0172, -0.0367, -0.0416, -0.0076, -0.0117,  0.0408,  0.0463,  0.0186,\n",
            "        -0.0322, -0.0070, -0.0283, -0.0251, -0.0203,  0.0478, -0.0155, -0.0433,\n",
            "         0.0228, -0.0334,  0.0200,  0.0117, -0.0340,  0.0442,  0.0295,  0.0028,\n",
            "        -0.0163, -0.0061, -0.0165,  0.0033, -0.0296,  0.0405, -0.0246,  0.0036,\n",
            "        -0.0099,  0.0371, -0.0284,  0.0113, -0.0073,  0.0344,  0.0117, -0.0186,\n",
            "         0.0397, -0.0197,  0.0447, -0.0011,  0.0336, -0.0274,  0.0196,  0.0385,\n",
            "         0.0148, -0.0281, -0.0091,  0.0221,  0.0279, -0.0027, -0.0336, -0.0287,\n",
            "        -0.0260, -0.0248, -0.0393,  0.0386,  0.0237,  0.0179, -0.0275,  0.0172,\n",
            "         0.0403, -0.0379, -0.0293,  0.0098, -0.0424, -0.0118, -0.0389,  0.0310,\n",
            "         0.0453, -0.0330, -0.0127, -0.0138,  0.0179,  0.0291, -0.0275, -0.0217,\n",
            "        -0.0281, -0.0246,  0.0240,  0.0073, -0.0144, -0.0263,  0.0137,  0.0091,\n",
            "         0.0085, -0.0408,  0.0066,  0.0010,  0.0463, -0.0030, -0.0055,  0.0067,\n",
            "         0.0329, -0.0213, -0.0053,  0.0647,  0.0156, -0.0387,  0.0105, -0.0427,\n",
            "        -0.0315, -0.0099, -0.0234, -0.0067, -0.0213, -0.0321, -0.0246,  0.0394,\n",
            "         0.0225, -0.0320, -0.0234, -0.0121,  0.0318,  0.0276,  0.0363,  0.0212,\n",
            "        -0.0188,  0.0481, -0.0058, -0.0048,  0.0205,  0.0198,  0.0295, -0.0315,\n",
            "        -0.0120, -0.0334, -0.0298,  0.0300,  0.0253,  0.0353,  0.0297, -0.0356,\n",
            "         0.0339, -0.0402,  0.0188,  0.0184,  0.0045, -0.0207, -0.0225,  0.0380,\n",
            "        -0.0018, -0.0313,  0.0087,  0.0423,  0.0006, -0.0364, -0.0346, -0.0222,\n",
            "         0.0141, -0.0454,  0.0213,  0.0326,  0.0397,  0.0295,  0.0234, -0.0237,\n",
            "        -0.0080,  0.0080,  0.0354,  0.0016, -0.0380,  0.0498, -0.0224, -0.0446,\n",
            "        -0.0067,  0.0097,  0.0311,  0.0315, -0.0278,  0.0323,  0.0083, -0.0183,\n",
            "        -0.0086,  0.0263, -0.0253,  0.0304, -0.0415,  0.0043, -0.0087,  0.0406,\n",
            "        -0.0339,  0.0236, -0.0259, -0.0108, -0.0226,  0.0610, -0.0048, -0.0144,\n",
            "        -0.0214,  0.0381, -0.0512, -0.0104,  0.0396, -0.0275,  0.0191, -0.0288,\n",
            "        -0.0207,  0.0494,  0.0257,  0.0487,  0.0404,  0.0019,  0.0175,  0.0031,\n",
            "        -0.0021, -0.0007, -0.0095,  0.0413, -0.0178, -0.0243, -0.0412, -0.0236,\n",
            "         0.0355,  0.0322, -0.0236,  0.0094,  0.0237,  0.0387, -0.0318,  0.0542,\n",
            "         0.0230,  0.0343,  0.0149,  0.0352, -0.0298,  0.0464, -0.0108,  0.0325,\n",
            "        -0.0165, -0.0137, -0.0433, -0.0086,  0.0105,  0.0326,  0.0140, -0.0016,\n",
            "         0.0359, -0.0332,  0.0272, -0.0057,  0.0165,  0.0060, -0.0204, -0.0191,\n",
            "         0.0229, -0.0114, -0.0062, -0.0147,  0.0157, -0.0421, -0.0013, -0.0005,\n",
            "        -0.0376, -0.0176,  0.0390,  0.0377,  0.0070,  0.0384,  0.0178,  0.0038,\n",
            "         0.0332, -0.0025,  0.0484,  0.0031, -0.0278,  0.0125,  0.0183, -0.0120,\n",
            "         0.0123, -0.0265,  0.0389,  0.0163, -0.0194, -0.0237,  0.0050,  0.0202,\n",
            "         0.0142, -0.0412, -0.0027, -0.0187, -0.0394,  0.0546,  0.0366,  0.0115,\n",
            "        -0.0096,  0.0193,  0.0530,  0.0288,  0.0149,  0.0133, -0.0379,  0.0194,\n",
            "        -0.0232, -0.0304,  0.0351,  0.0175,  0.0113, -0.0356,  0.0379,  0.0222,\n",
            "         0.0393,  0.0169,  0.0428, -0.0148, -0.0203,  0.0312,  0.0143, -0.0269,\n",
            "         0.0469,  0.0438, -0.0409,  0.0075, -0.0340, -0.0317,  0.0405, -0.0286,\n",
            "        -0.0072,  0.0153, -0.0142,  0.0310,  0.0089,  0.0257, -0.0250,  0.0255,\n",
            "        -0.0255,  0.0200, -0.0252, -0.0298,  0.0009,  0.0163, -0.0136, -0.0339,\n",
            "         0.0247, -0.0365,  0.0192,  0.0321,  0.0230,  0.0006,  0.0203,  0.0160,\n",
            "        -0.0046,  0.0324, -0.0157, -0.0341,  0.0520,  0.0074,  0.0093, -0.0433],\n",
            "       device='cuda:0')), ('linear_relu_stack.4.weight', tensor([[-0.0125,  0.0184, -0.0198,  ...,  0.0294,  0.0012, -0.0450],\n",
            "        [-0.0226,  0.0257, -0.0162,  ..., -0.0279, -0.0404, -0.0218],\n",
            "        [ 0.0211,  0.0165,  0.0101,  ...,  0.0267, -0.0084, -0.0040],\n",
            "        ...,\n",
            "        [ 0.0248,  0.0068,  0.0106,  ..., -0.0253,  0.0228, -0.0004],\n",
            "        [-0.0622,  0.0190, -0.0139,  ..., -0.0213, -0.0232, -0.0089],\n",
            "        [-0.0610, -0.0075, -0.0484,  ...,  0.0100, -0.0226, -0.0377]],\n",
            "       device='cuda:0')), ('linear_relu_stack.4.bias', tensor([-0.0421,  0.0117, -0.0384, -0.0250, -0.0444,  0.1810, -0.0281,  0.0821,\n",
            "        -0.0310, -0.0311], device='cuda:0'))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o3LLeMvAPlrR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}